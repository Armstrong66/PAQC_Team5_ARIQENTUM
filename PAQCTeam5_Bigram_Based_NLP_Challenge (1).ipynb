{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries and dependencies"
      ],
      "metadata": {
        "id": "eo51wKOHfpfY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ELdPvjHakyz"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "import os, re, gc\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter, defaultdict\n",
        "# from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "d8r_3UELaqPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading the data and setting directory"
      ],
      "metadata": {
        "id": "TBoRnCNqkPAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the Google Drive ID and Output Filename\n",
        "file_id = '1feOAkOhNhxbF9RgD-eR1icyQHY3MbDor'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "# 2. Define where we want the data to live\n",
        "data_folder = 'bigrams_dataset_folder'\n",
        "csv_filename = 'bigrams_data.csv'\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "os.makedirs(data_folder, exist_ok=True)\n",
        "\n",
        "# 3. Download the file directly into that folder\n",
        "output_path = os.path.join(data_folder, csv_filename)\n",
        "\n",
        "if not os.path.exists(output_path):\n",
        "  print(\"Downloading CSV file...\")\n",
        "  gdown.download(url, output_path, quiet=False)\n",
        "  print(\"Download complete.\")\n",
        "else:\n",
        "  print(\"File already exists. Skipping download.\")\n",
        "\n",
        "# 4. Set the Project Root to the LOCAL folder\n",
        "PROJECT_ROOT = Path(data_folder)\n",
        "\n",
        "# Walk the directory tree\n",
        "def walk_tree(root, max_depth=3):\n",
        "    print(f\"Scanning directory: {root}\")\n",
        "    for path in root.rglob('*'):\n",
        "        # Ensure we don't go too deep\n",
        "        if len(path.relative_to(root).parts) <= max_depth:\n",
        "            print(f\"Found file: {path}\")\n",
        "\n",
        "# Run it\n",
        "walk_tree(PROJECT_ROOT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMkSfPvga9ew",
        "outputId": "3d2c7cd7-c808-494a-ed2f-92901c5b5249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading CSV file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1feOAkOhNhxbF9RgD-eR1icyQHY3MbDor\n",
            "From (redirected): https://drive.google.com/uc?id=1feOAkOhNhxbF9RgD-eR1icyQHY3MbDor&confirm=t&uuid=de61781b-7131-40ed-8f58-297dd2778da8\n",
            "To: /content/bigrams_dataset_folder/bigrams_data.csv\n",
            "100%|██████████| 200M/200M [00:02<00:00, 85.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete.\n",
            "Scanning directory: bigrams_dataset_folder\n",
            "Found file: bigrams_dataset_folder/bigrams_data.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Confirming the downloaded file\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT\n",
        "csv_files = list(DATA_DIR.glob(\"*.csv\"))\n",
        "\n",
        "if not csv_files:\n",
        "  print(\"No CSV files found! Check your folder path.\")\n",
        "else:\n",
        "  print(f\"Found {len(csv_files)} files(s):\")\n",
        "  for file in csv_files:\n",
        "    print(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DGdGUWDb7Em",
        "outputId": "3c2916aa-01e7-46d6-daf1-e06d4144f297",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1 files(s):\n",
            "bigrams_dataset_folder/bigrams_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CSV Safe loading (Inspecting headers only)"
      ],
      "metadata": {
        "id": "1PHLsCX3kgJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eda_summary = {}  # dictionary for saving eda results down the pipeline\n",
        "csv_path = csv_files[0]\n",
        "pd.read_csv(csv_path, nrows=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "hG4lPzt5d9Pv",
        "outputId": "c64e8ad9-3e87-4722-807a-ecbbde74fdfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ngram lang  lang_id  count\n",
              "0  BIRIBIARA wɔ  twi        1      1\n",
              "1         wɔ ne  twi        1   8972\n",
              "2       ne bere  twi        1   2980\n",
              "3        bere a  twi        1  36770\n",
              "4      a wɔahyɛ  twi        1    859\n",
              "5    wɔahyɛ ato  twi        1     63\n",
              "6        ato hɔ  twi        1    907\n",
              "7         hɔ na  twi        1   4633\n",
              "8        na ade  twi        1    387\n",
              "9     ade biara  twi        1    202"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73372913-3d1c-4fce-a7e7-8c0ffbe1c0a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ngram</th>\n",
              "      <th>lang</th>\n",
              "      <th>lang_id</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BIRIBIARA wɔ</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wɔ ne</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>8972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ne bere</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>2980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bere a</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>36770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a wɔahyɛ</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>wɔahyɛ ato</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ato hɔ</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>hɔ na</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>4633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>na ade</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ade biara</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73372913-3d1c-4fce-a7e7-8c0ffbe1c0a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-73372913-3d1c-4fce-a7e7-8c0ffbe1c0a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-73372913-3d1c-4fce-a7e7-8c0ffbe1c0a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4589d1d3-3a22-443b-9d79-9cf70745c0d3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4589d1d3-3a22-443b-9d79-9cf70745c0d3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4589d1d3-3a22-443b-9d79-9cf70745c0d3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"ngram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"na ade\",\n          \"w\\u0254 ne\",\n          \"w\\u0254ahy\\u025b ato\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"twi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11321,\n        \"min\": 1,\n        \"max\": 36770,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          387\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Confirming the file size (useful for speed inference)\n",
        "\n",
        "file_size_mb = csv_path.stat().st_size / (1024 ** 2)\n",
        "print(f\"{file_size_mb} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h43Wl7pTkHvq",
        "outputId": "17a5ed81-6161-41a9-d9fc-5c5db2f464f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "191.14224529266357 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Chunked loading (EDA-safe)\n",
        "\n",
        "CHUNK_SIZE = 200_000\n",
        "chunks = pd.read_csv(csv_path, chunksize=CHUNK_SIZE)\n",
        "\n",
        "# for chunk in chunks:\n",
        "#   print(f\"Processing a chunk of files: {chunk.shape}\")  # suffers out-of-memory problem after some time\n",
        "\n",
        "first_chunk = next(chunks)\n",
        "first_chunk.tail()  # also check tail using \".tail\""
      ],
      "metadata": {
        "id": "_RkcWVW2ldNC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "354870fd-23e7-4342-9575-0c2c0db82da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               ngram lang  lang_id  count\n",
              "199995  wɔamfa honam  twi        1      3\n",
              "199996   nipadua bio  twi        1      8\n",
              "199997   sɛnea wɔyɛe  twi        1     24\n",
              "199998   Eunice Dabi  twi        1      4\n",
              "199999    Dabi misua  twi        1      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f37f11e-1133-420a-aa64-989cab747e33\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ngram</th>\n",
              "      <th>lang</th>\n",
              "      <th>lang_id</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>199995</th>\n",
              "      <td>wɔamfa honam</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199996</th>\n",
              "      <td>nipadua bio</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199997</th>\n",
              "      <td>sɛnea wɔyɛe</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199998</th>\n",
              "      <td>Eunice Dabi</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199999</th>\n",
              "      <td>Dabi misua</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f37f11e-1133-420a-aa64-989cab747e33')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f37f11e-1133-420a-aa64-989cab747e33 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f37f11e-1133-420a-aa64-989cab747e33');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5b9ace4c-0ea7-4d70-9046-f9b81e2fc6bd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b9ace4c-0ea7-4d70-9046-f9b81e2fc6bd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5b9ace4c-0ea7-4d70-9046-f9b81e2fc6bd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"first_chunk\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"ngram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"nipadua bio\",\n          \"Dabi misua\",\n          \"s\\u025bnea w\\u0254y\\u025be\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"twi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 1,\n        \"max\": 24,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Structural EDA (to confirm what we are dealing with)"
      ],
      "metadata": {
        "id": "dUavcbvinUSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Basic schema\n",
        "first_chunk.info()  # data types: 2 integers, 2 str/objects"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVmoSOZAm0RC",
        "outputId": "acf4364a-7351-453e-d1b2-290647458a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 200000 entries, 0 to 199999\n",
            "Data columns (total 4 columns):\n",
            " #   Column   Non-Null Count   Dtype \n",
            "---  ------   --------------   ----- \n",
            " 0   ngram    200000 non-null  object\n",
            " 1   lang     200000 non-null  object\n",
            " 2   lang_id  200000 non-null  int64 \n",
            " 3   count    200000 non-null  int64 \n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 6.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Missing values check\n",
        "first_chunk.isna().sum()  # none"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "9a5p7bKxneTS",
        "outputId": "6c3e922a-ba7d-4561-9008-1d41de737134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ngram      0\n",
              "lang       0\n",
              "lang_id    0\n",
              "count      0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ngram</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lang</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lang_id</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Unique languages\n",
        "first_chunk[\"lang\"].unique()  # the dataset is twi-heavy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8PmeSOun_ct",
        "outputId": "43b58be4-77bf-4f77-da68-b76cd03db289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['twi'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Language distribution (global, chunked)"
      ],
      "metadata": {
        "id": "7XoGexgEod_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### We accumulate counts without loading full CSV into memory\n",
        "# the insights derived here directly affects smoothing, priors and scoring bias\n",
        "from collections import Counter\n",
        "\n",
        "lang_counter = Counter()\n",
        "lang_id_counter = Counter()\n",
        "total_rows = 0\n",
        "\n",
        "for chunk in pd.read_csv(csv_path, chunksize=CHUNK_SIZE):\n",
        "  lang_counter.update(chunk[\"lang\"])\n",
        "  lang_id_counter.update(chunk[\"lang_id\"])\n",
        "  total_rows += len(chunk)\n",
        "\n",
        "lang_counter, lang_id_counter, total_rows  # output line"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ujdi29vWoVMj",
        "outputId": "018c4079-b9fb-43dd-ec98-7bb548ce32f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Counter({'twi': 2946491, 'eng': 3308262, 'fra': 3004308}),\n",
              " Counter({1: 2946491, 2: 3308262, 3: 3004308}),\n",
              " 9259061)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### populate eda_summary during chunked EDA\n",
        "eda_summary[\"language_distribution\"] = dict(lang_counter)\n",
        "eda_summary[\"language_id_distribution\"] = dict(lang_id_counter)\n",
        "eda_summary[\"total_rows\"] = total_rows"
      ],
      "metadata": {
        "id": "D31PfKjxWyyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bigram Quality Analysis"
      ],
      "metadata": {
        "id": "L_8A__Uwp8UU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Split bigrams safely\n",
        "\n",
        "def split_bigram(ngram):\n",
        "  parts = ngram.split()\n",
        "  return parts if len(parts) == 2 else None\n",
        "\n",
        "first_chunk[\"bigram_parts\"] = first_chunk[\"ngram\"].apply(split_bigram)\n",
        "first_chunk[\"valid_bigram\"] = first_chunk[\"bigram_parts\"].notnull()\n",
        "first_chunk[\"valid_bigram\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "BaTVp23ZpqBv",
        "outputId": "3f08a3b4-255c-4422-bee6-b2cab68d95e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "valid_bigram\n",
              "True    200000\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>valid_bigram</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <td>200000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Character-level inspection (for twi)\n",
        "\n",
        "import re\n",
        "def contains_non_ascii(text):\n",
        "  return bool(re.search(r\"[^\\x00-\\x7F]\", text))\n",
        "\n",
        "first_chunk[\"non_ascii\"] = first_chunk[\"ngram\"].apply(contains_non_ascii)\n",
        "first_chunk[\"non_ascii\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "fSdQvDlMq5UG",
        "outputId": "a799ccda-bf34-4d1c-efde-97cd0006664e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "non_ascii\n",
              "True     103389\n",
              "False     96611\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>non_ascii</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <td>103389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>False</th>\n",
              "      <td>96611</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Detect suspicious language-mixing bigrams\n",
        "\n",
        "def contains_language_names(text):\n",
        "  keywords = [\n",
        "      \"English\", \"French\", \"German\", \"Spanish\", \"Dutch\",\n",
        "      \"Italian\", \"Portuguese\", \"Russian\", \"Japanese\", \"Korean\",\n",
        "      \"Arabic\", \"Chinese\", \"Hindi\", \"Bengali\", \"Tamil\", \"Telugu\",\n",
        "      \"Bulgarian\", \"Catalan\", \"Czech\", \"Danish\", \"Greek\", \"Hungarian\",\n",
        "      \"Polish\", \"Romanian\", \"Swedish\", \"Turkish\", \"Cantonese\"\n",
        "  ]\n",
        "  return any(k.lower() in text.lower() for k in keywords)\n",
        "\n",
        "first_chunk[\"language_name_bigram\"] = first_chunk[\"ngram\"].apply(contains_language_names)\n",
        "first_chunk[first_chunk[\"language_name_bigram\"]].head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "cq8MBalvsCEN",
        "outputId": "1cde6771-7a13-448c-9425-582d16942881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     ngram lang  lang_id  count            bigram_parts  \\\n",
              "3297             ne Arabic  twi        1      5            [ne, Arabic]   \n",
              "3298   Arabic akontaahyɛde  twi        1      4  [Arabic, akontaahyɛde]   \n",
              "7748            wɔ Germany  twi        1    198           [wɔ, Germany]   \n",
              "7839             na German  twi        1     12            [na, German]   \n",
              "7840        German asraafo  twi        1     41       [German, asraafo]   \n",
              "9945            ne Germany  twi        1     23           [ne, Germany]   \n",
              "9946           Germany yɛɛ  twi        1      3          [Germany, yɛɛ]   \n",
              "9950          wɔmaa German  twi        1      1         [wɔmaa, German]   \n",
              "14791    Nuremberg Germany  twi        1      7    [Nuremberg, Germany]   \n",
              "14792           Germany wɔ  twi        1     39           [Germany, wɔ]   \n",
              "\n",
              "       valid_bigram  non_ascii  language_name_bigram  \n",
              "3297           True      False                  True  \n",
              "3298           True       True                  True  \n",
              "7748           True       True                  True  \n",
              "7839           True      False                  True  \n",
              "7840           True      False                  True  \n",
              "9945           True      False                  True  \n",
              "9946           True       True                  True  \n",
              "9950           True       True                  True  \n",
              "14791          True      False                  True  \n",
              "14792          True       True                  True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81d4ccf1-4e13-42e9-b641-ef51ae61f025\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ngram</th>\n",
              "      <th>lang</th>\n",
              "      <th>lang_id</th>\n",
              "      <th>count</th>\n",
              "      <th>bigram_parts</th>\n",
              "      <th>valid_bigram</th>\n",
              "      <th>non_ascii</th>\n",
              "      <th>language_name_bigram</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3297</th>\n",
              "      <td>ne Arabic</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>[ne, Arabic]</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3298</th>\n",
              "      <td>Arabic akontaahyɛde</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>[Arabic, akontaahyɛde]</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7748</th>\n",
              "      <td>wɔ Germany</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>198</td>\n",
              "      <td>[wɔ, Germany]</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7839</th>\n",
              "      <td>na German</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>[na, German]</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7840</th>\n",
              "      <td>German asraafo</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>[German, asraafo]</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9945</th>\n",
              "      <td>ne Germany</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>[ne, Germany]</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9946</th>\n",
              "      <td>Germany yɛɛ</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>[Germany, yɛɛ]</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9950</th>\n",
              "      <td>wɔmaa German</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[wɔmaa, German]</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14791</th>\n",
              "      <td>Nuremberg Germany</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>[Nuremberg, Germany]</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14792</th>\n",
              "      <td>Germany wɔ</td>\n",
              "      <td>twi</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>[Germany, wɔ]</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81d4ccf1-4e13-42e9-b641-ef51ae61f025')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-81d4ccf1-4e13-42e9-b641-ef51ae61f025 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-81d4ccf1-4e13-42e9-b641-ef51ae61f025');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-52d0fa4d-bc96-4f80-80e5-2c0d5a43790a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-52d0fa4d-bc96-4f80-80e5-2c0d5a43790a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-52d0fa4d-bc96-4f80-80e5-2c0d5a43790a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"first_chunk[first_chunk[\\\"language_name_bigram\\\"]]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"ngram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Nuremberg Germany\",\n          \"Arabic akontaahy\\u025bde\",\n          \"ne Germany\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"twi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59,\n        \"min\": 1,\n        \"max\": 198,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bigram_parts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"valid_bigram\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"non_ascii\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"language_name_bigram\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Populating bigram validity & noise (from sample chunk)\n",
        "eda_summary[\"sample_bigram_stats\"] = {\n",
        "    \"total_bigrams\": len(first_chunk),\n",
        "    \"valid_bigrams\": int(first_chunk[\"valid_bigram\"].sum()),\n",
        "    \"invalid_bigrams\": int((~first_chunk[\"valid_bigram\"]).sum()),\n",
        "    \"non_ascii_bigrams\": int(first_chunk[\"non_ascii\"].sum()),\n",
        "    \"language_name_bigrams\": int(first_chunk[\"language_name_bigram\"].sum())\n",
        "}"
      ],
      "metadata": {
        "id": "_hBLO3LfZqeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Count distribution (why smoothing is mandatory)\n",
        "first_chunk[\"count\"].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "tNotZoXMtv0i",
        "outputId": "4bf1f37b-8654-46f3-d556-724dbfe584a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    200000.000000\n",
              "mean         61.188075\n",
              "std         522.495109\n",
              "min           1.000000\n",
              "25%           2.000000\n",
              "50%           7.000000\n",
              "75%          28.000000\n",
              "max       81971.000000\n",
              "Name: count, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>200000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>61.188075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>522.495109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>28.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>81971.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### inspecting long tail\n",
        "first_chunk[\"count\"].value_counts().head(10)\n",
        "\n",
        "# This reveals/confirms the classical NLP problem termed, \"Zipf's law\"\n",
        "# That is:\n",
        "  # Many bigrams with count = 1 or 2 or 3 (biased count)\n",
        "  # Few with extremely large counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "1XdGuGw0uTE4",
        "outputId": "2e5c9379-3318-4c7c-a96c-2c5723d040f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count\n",
              "1     41940\n",
              "2     18088\n",
              "3     12746\n",
              "4      9436\n",
              "5      7464\n",
              "6      6431\n",
              "7      5445\n",
              "8      4920\n",
              "9      4181\n",
              "10     3860\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>7464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Count Statistics\n",
        "eda_summary[\"count_statistics\"] = {\n",
        "    \"min\": int(first_chunk[\"count\"].min()),\n",
        "    \"max\": int(first_chunk[\"count\"].max()),\n",
        "    \"mean\": int(first_chunk[\"count\"].max()),\n",
        "    \"median\": int(first_chunk[\"count\"].median()),\n",
        "    \"std\": float(first_chunk[\"count\"].std()),\n",
        "    \"percentiles\": {\n",
        "        \"p50\": float(first_chunk[\"count\"].quantile(0.50)),\n",
        "        \"p75\": float(first_chunk[\"count\"].quantile(0.75)),\n",
        "        \"p90\": float(first_chunk[\"count\"].quantile(0.90)),\n",
        "        \"p99\": float(first_chunk[\"count\"].quantile(0.99)),\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "mlZ7LYcSul_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving EDA results (dict) to memory/disk"
      ],
      "metadata": {
        "id": "krNLiRLdgEr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### JSON format\n",
        "with open(\"eda_summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "  json.dump(eda_summary, f, indent=4, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "LBkehslUfdC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Markdown format\n",
        "def eda_to_markdown(summary):\n",
        "  lines = []\n",
        "  lines.append(\"# EDA Summary\\n\")\n",
        "\n",
        "  lines.append(\"## Language Distribution\")\n",
        "  for k, v in summary[\"language_distribution\"].items():\n",
        "    lines.append(f\"- {k}: {v}\")\n",
        "\n",
        "  lines.append(\"\\n## Sample Bigram Quality\")\n",
        "  for k, v in summary[\"sample_bigram_stats\"].items():\n",
        "    lines.append(f\"- {k}: {v}\")\n",
        "\n",
        "  lines.append(\"\\n## Count Statistics\")\n",
        "  for k, v, in summary[\"count_statistics\"].items():\n",
        "    lines.append(f\"- {k}: {v}\")\n",
        "\n",
        "  return \"\\n\".join(lines)\n",
        "\n",
        "with open(\"eda_summary.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "  f.write(eda_to_markdown(eda_summary))"
      ],
      "metadata": {
        "id": "olhtOME1hmfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantum-Inspired Bigram Language Identifiers"
      ],
      "metadata": {
        "id": "fXkqx7hBEHjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Core Model for both single and multiple sentence ID"
      ],
      "metadata": {
        "id": "6xMuvurYyL9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QISingleLID:\n",
        "  model_type = \"qi\"\n",
        "  \"\"\"\n",
        "  Quantum-inspired bigram language identifier using\n",
        "  state overlap instead of log-likelihoods (sparse, normalized and fast).\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, bigrams_csv, alpha=1.0):\n",
        "    print(\"Loading and building quantum-inspired language states...\")\n",
        "\n",
        "    df = pd.read_csv(\n",
        "        bigrams_csv,\n",
        "        usecols=[\"lang_id\", \"lang\", \"ngram\", \"count\"],\n",
        "        dtype={\n",
        "            \"lang_id\": \"int16\",\n",
        "            \"lang\": \"category\",\n",
        "            \"ngram\": \"object\",\n",
        "            \"count\": \"int32\",\n",
        "        }\n",
        "        )\n",
        "\n",
        "    self.lang_id_to_name = {}\n",
        "    self.lang_states = {}   # lang_id -> {bigram: amplitude}\n",
        "    self.languages = []\n",
        "    self.unk_amp = {}   # lang_id -> amplitude\n",
        "\n",
        "    # Build state vector per language\n",
        "    for lang_id, group in df.groupby(\"lang_id\"):\n",
        "      lang_name = group[\"lang\"].iloc[0]\n",
        "      self.lang_id_to_name[lang_id] = lang_name\n",
        "      self.languages.append(lang_id)\n",
        "\n",
        "      counts = group.set_index(\"ngram\")[\"count\"].to_dict()\n",
        "      total = sum(counts.values()) + alpha * len(counts)\n",
        "\n",
        "      self.unk_amp[lang_id] = math.sqrt(alpha / total)\n",
        "\n",
        "      # Compute sqrt-prob amplitudes\n",
        "      state = {}\n",
        "      for bigram, count in counts.items():\n",
        "        prob = (count + alpha) / total\n",
        "        state[bigram] = math.sqrt(prob)\n",
        "\n",
        "      # L2 normalize language state (safety)\n",
        "      norm = math.sqrt(sum(v*v for v in state.values()))\n",
        "      for b in state:\n",
        "        state[b] /= norm\n",
        "\n",
        "      self.lang_states[lang_id] = state\n",
        "\n",
        "    self.word_re = re.compile(r\"\\w+\", flags=re.UNICODE)\n",
        "\n",
        "    del df\n",
        "    gc.collect()\n",
        "    print(f\"Loaded {len(self.languages)} language states.\")\n",
        "\n",
        "  # === Sentence -> State Encoding (Sparse)\n",
        "  def extract_bigrams(self, text):\n",
        "    words = self.word_re.findall(text)\n",
        "    return [f\"{words[i]} {words[i+1]}\" for i in range(len(words) - 1)]\n",
        "\n",
        "  def sentence_state(self, text):\n",
        "    bigrams = self.extract_bigrams(text)\n",
        "    if not bigrams:\n",
        "      return None\n",
        "\n",
        "    freq = defaultdict(int)\n",
        "    for b in bigrams:\n",
        "      freq[b] += 1\n",
        "\n",
        "    total = sum(freq.values())\n",
        "\n",
        "    # sqrt frequency amplitudes\n",
        "    state = {b: math.sqrt(c / total) for b, c in freq.items()}\n",
        "\n",
        "    # normalize sentence state (quantum state preparation)\n",
        "    norm = math.sqrt(sum(v * v for v in state.values()))\n",
        "    for b in state:\n",
        "      state[b] /= norm\n",
        "\n",
        "    return state\n",
        "\n",
        "  # === Quantum-Inspired Measurement (Fast Overlap)\n",
        "  def predict(self, text):\n",
        "    s_state = self.sentence_state(text)\n",
        "    if s_state is None:\n",
        "      return None, {}\n",
        "\n",
        "    best_lang = None\n",
        "    best_score = -1.0\n",
        "    scores = {}\n",
        "\n",
        "    for lang_id in self.languages:\n",
        "      l_state = self.lang_states[lang_id]\n",
        "      unk = self.unk_amp[lang_id]   # assign a small non-zero amplitude when a bigram is unseen\n",
        "\n",
        "      # dot product over sentence support only\n",
        "      overlap = 0.0\n",
        "      for b, a_s in s_state.items():\n",
        "        overlap += a_s * l_state.get(b, unk)\n",
        "\n",
        "      score = overlap  # linear overlap (stable + fast)\n",
        "      lang = self.lang_id_to_name[lang_id]\n",
        "      scores[lang] = score\n",
        "\n",
        "      # return raw predictions\n",
        "      if score > best_score:\n",
        "        best_score = score\n",
        "        best_lang = self.lang_id_to_name[lang_id]\n",
        "\n",
        "    # print(\"[def predict] Sentence bigrams:\", list(s_state.keys())[:10])\n",
        "\n",
        "    return best_lang, scores\n",
        "\n",
        "  # === Multiple-Sentence Inference\n",
        "  def predict_multiple(self, texts):\n",
        "    preds, scores = [], []\n",
        "    for t in texts:\n",
        "        p, s = self.predict(t)\n",
        "        preds.append(p)\n",
        "        scores.append(s)\n",
        "    return preds, scores"
      ],
      "metadata": {
        "id": "N7gdYL7DEHBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantum-Inspired Model Extension for Batch Inference"
      ],
      "metadata": {
        "id": "YcF1s5U81xXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QIBatchLID:\n",
        "    model_type = \"qi\"\n",
        "    \"\"\"\n",
        "    Quantum-inspired bigram language identifier using\n",
        "    state overlap (Hilbert-space similarity).\n",
        "    Optimized for single and multiple sentence inference.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, bigrams_csv, alpha=1.0):\n",
        "        print(\"Loading and building quantum-inspired language states...\")\n",
        "\n",
        "        df = pd.read_csv(\n",
        "            bigrams_csv,\n",
        "            usecols=[\"lang_id\", \"lang\", \"ngram\", \"count\"],\n",
        "            dtype={\n",
        "                \"lang_id\": \"int16\",\n",
        "                \"lang\": \"category\",\n",
        "                \"ngram\": \"object\",\n",
        "                \"count\": \"int32\",\n",
        "            }\n",
        "        )\n",
        "\n",
        "        self.lang_id_to_name = {}\n",
        "        self.languages = []\n",
        "\n",
        "        # ---- Build normalized language states\n",
        "        lang_states = {}\n",
        "\n",
        "        for lang_id, group in df.groupby(\"lang_id\"):\n",
        "            lang_name = group[\"lang\"].iloc[0]\n",
        "            self.lang_id_to_name[lang_id] = lang_name\n",
        "            self.languages.append(lang_id)\n",
        "\n",
        "            counts = group.set_index(\"ngram\")[\"count\"].to_dict()\n",
        "            total = sum(counts.values()) + alpha * len(counts)\n",
        "\n",
        "            state = {\n",
        "                b: math.sqrt((c + alpha) / total)\n",
        "                for b, c in counts.items()\n",
        "            }\n",
        "\n",
        "            # Normalize once\n",
        "            norm = math.sqrt(sum(v * v for v in state.values()))\n",
        "            for b in state:\n",
        "                state[b] /= norm\n",
        "\n",
        "            lang_states[lang_id] = state\n",
        "\n",
        "        # ---- Build shared vocabulary\n",
        "        self.vocab = list(\n",
        "            set(b for s in lang_states.values() for b in s)\n",
        "        )\n",
        "        self.vocab_index = {b: i for i, b in enumerate(self.vocab)}\n",
        "\n",
        "        # ---- Dense language matrix (L x V)\n",
        "        self.lang_matrix = np.zeros(\n",
        "            (len(self.languages), len(self.vocab)),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "        for i, lang_id in enumerate(self.languages):\n",
        "            for b, amp in lang_states[lang_id].items():\n",
        "                self.lang_matrix[i, self.vocab_index[b]] = amp\n",
        "\n",
        "        self.lang_matrix = self.lang_matrix / np.linalg.norm(\n",
        "            self.lang_matrix, axis=1, keepdims=True\n",
        "        )\n",
        "\n",
        "        self.word_re = re.compile(r\"\\w+\", flags=re.UNICODE)\n",
        "\n",
        "        del df\n",
        "        gc.collect()\n",
        "\n",
        "        print(f\"Loaded {len(self.languages)} language states.\")\n",
        "\n",
        "    # ---------- Encoding ----------\n",
        "    def extract_bigrams(self, text):\n",
        "        words = self.word_re.findall(text.lower())\n",
        "        return [f\"{words[i]} {words[i+1]}\" for i in range(len(words) - 1)]\n",
        "\n",
        "    def sentence_vector(self, text):\n",
        "        bigrams = self.extract_bigrams(text)\n",
        "        if not bigrams:\n",
        "            return None\n",
        "\n",
        "        freq = defaultdict(int)\n",
        "        for b in bigrams:\n",
        "            freq[b] += 1\n",
        "\n",
        "        vec = np.zeros(len(self.vocab), dtype=np.float32)\n",
        "        total = sum(freq.values())\n",
        "\n",
        "        for b, c in freq.items():\n",
        "            idx = self.vocab_index.get(b)\n",
        "            if idx is not None:\n",
        "                vec[idx] = math.sqrt(c / total)\n",
        "\n",
        "        norm = np.linalg.norm(vec)\n",
        "        return vec / norm if norm > 0 else None\n",
        "\n",
        "    def encode_sentences(self, texts):\n",
        "        \"\"\"\n",
        "        Encode multiple sentences into a matrix (N x V).\n",
        "        \"\"\"\n",
        "        vectors = []\n",
        "        valid_indices = []\n",
        "\n",
        "        for i, t in enumerate(texts):\n",
        "            v = self.sentence_vector(t)\n",
        "            if v is not None:\n",
        "                vectors.append(v)\n",
        "                valid_indices.append(i)\n",
        "\n",
        "        if not vectors:\n",
        "            return None, []\n",
        "\n",
        "        return np.vstack(vectors), valid_indices\n",
        "\n",
        "    # ---------- Prediction ----------\n",
        "    def predict(self, text):\n",
        "        v = self.sentence_vector(text)\n",
        "        if v is None:\n",
        "            return None, {}\n",
        "\n",
        "        overlaps = self.lang_matrix @ v\n",
        "        scores = overlaps ** 2\n",
        "\n",
        "        best_idx = int(np.argmax(scores))\n",
        "        pred = self.lang_id_to_name[self.languages[best_idx]]\n",
        "\n",
        "        return pred, {\n",
        "            self.lang_id_to_name[self.languages[i]]: float(scores[i])\n",
        "            for i in range(len(scores))\n",
        "        }\n",
        "\n",
        "    def predict_multiple(self, texts):\n",
        "        \"\"\"\n",
        "        True multi-sentence inference (vectorized).\n",
        "        \"\"\"\n",
        "        X, valid_idx = self.encode_sentences(texts)\n",
        "        if X is None:\n",
        "            return [], []\n",
        "\n",
        "        overlaps = X @ self.lang_matrix.T      # (N x L)\n",
        "        scores = overlaps ** 2\n",
        "\n",
        "        preds = []\n",
        "        scores_list = []\n",
        "\n",
        "        for i in range(scores.shape[0]):\n",
        "            best = int(np.argmax(scores[i]))\n",
        "            preds.append(self.lang_id_to_name[self.languages[best]])\n",
        "            scores_list.append({\n",
        "                self.lang_id_to_name[self.languages[j]]: float(scores[i, j])\n",
        "                for j in range(scores.shape[1])\n",
        "            })\n",
        "\n",
        "        return preds, scores_list"
      ],
      "metadata": {
        "id": "H3y-B9ga12re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global safe, callable directory/path"
      ],
      "metadata": {
        "id": "U-rRoh2MW1gH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "DATA_DIR = Path(\"bigrams_dataset_folder\")\n",
        "\n",
        "def infer_single_csv(data_dir: Path) -> Path:\n",
        "    csvs = sorted(data_dir.glob(\"*.csv\"))\n",
        "\n",
        "    if len(csvs) == 0:\n",
        "        raise FileNotFoundError(\"❌ No CSV files found in data directory.\")\n",
        "\n",
        "    if len(csvs) > 1:\n",
        "        print(\"⚠️ Multiple CSV files found. Using the first one:\")\n",
        "        for c in csvs:\n",
        "            print(\"  -\", c.name)\n",
        "\n",
        "    return csvs[0]\n",
        "\n",
        "BIGRAMS_CSV_PATH = infer_single_csv(DATA_DIR)\n",
        "\n",
        "print(\"✅ Using dataset:\", BIGRAMS_CSV_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duXZrJz8W8AH",
        "outputId": "4bbf9092-4e77-4af2-f8b0-dd8b40b1f2df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Using dataset: bigrams_dataset_folder/bigrams_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Confirming dataset values/ids before inference/running\n",
        "required_cols = {\"lang_id\", \"lang\", \"ngram\", \"count\"}\n",
        "\n",
        "df_head = pd.read_csv(BIGRAMS_CSV_PATH, nrows=5)\n",
        "missing = required_cols - set(df_head.columns)\n",
        "\n",
        "if missing:\n",
        "    raise ValueError(f\"Missing required columns: {missing}\")\n",
        "\n",
        "print(\"✅ Dataset schema verified.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4oxQ1STXaIZ",
        "outputId": "806808e6-af20-49eb-87be-60cbe32616f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset schema verified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Evaluation/Performance Metrics"
      ],
      "metadata": {
        "id": "5GMnbEJZbkwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time, statistics, math\n",
        "\n",
        "### Function to normalize scores into a probability distribution\n",
        "def normalize_scores(scores, eps=1e-12):\n",
        "  total = sum(scores.values())\n",
        "  if total <= 0:\n",
        "    return {k: eps for k in scores}\n",
        "  probs = {k: max(v / total, eps) for k, v in scores.items()}\n",
        "  Z = sum(probs.values())\n",
        "  return {k: v / Z for k, v in probs.items()}\n",
        "\n",
        "### Function to select predict_multiple() if found in batch models\n",
        "def run_inference(model, texts):\n",
        "    if hasattr(model, \"predict_multiple\"):\n",
        "        return model.predict_multiple(texts)\n",
        "    else:\n",
        "        preds, scores = [], []\n",
        "        for t in texts:\n",
        "            p, s = model.predict(t)\n",
        "            preds.append(p)\n",
        "            scores.append(s)\n",
        "        return preds, scores\n",
        "\n",
        "### Negative Log Likelihood (NLL) loss function (for evaluation, not optimization)\n",
        "def nll_loss(probs, true_label, eps=1e-12):\n",
        "  p = probs.get(true_label, 0.0)\n",
        "  if p <= 0.0 or not np.isfinite(p):\n",
        "    p = eps\n",
        "  return -math.log(p)\n",
        "\n",
        "### 1. Accuracy\n",
        "def accuracy(preds, labels):\n",
        "  correct = sum(p == y for p, y in zip(preds, labels))\n",
        "  return correct / len(labels)\n",
        "\n",
        "### 2. NLL evaluation loss\n",
        "def mean_nll(model, texts, labels):\n",
        "  losses = []\n",
        "  for text, y in zip(texts, labels):\n",
        "    _, scores = run_inference(model, text)\n",
        "    probs = normalize_scores(scores)\n",
        "    losses.append(nll_loss(probs, y))\n",
        "  return sum(losses) / len(losses)\n",
        "\n",
        "### 3. Quantum Confidence Margin (QCM)\n",
        "def quantum_confidence_margin(scores):\n",
        "  vals = sorted(scores.values(), reverse=True)\n",
        "  return vals[0] - vals[1] if len(vals) > 1 else vals[0]\n",
        "\n",
        "### 4. Entropy (uncertainty)\n",
        "def entropy(probs, eps=1e-12):\n",
        "  return -sum(p * math.log(p + eps) for p in probs.values())\n",
        "\n",
        "### 5. Purity / Probability Mass Concentration (PMC)\n",
        "def purity(probs):\n",
        "  return sum(p * p for p in probs.values())\n",
        "\n",
        "### 6. Cross-lingual leakage\n",
        "def leakage(probs, pred_lang):\n",
        "  p_hat = probs[pred_lang]\n",
        "  return (sum(probs.values()) - p_hat) / (p_hat + 1e-12)\n",
        "\n",
        "### Inference latency\n",
        "def timed_predict(model, text):\n",
        "  start = time.perf_counter()\n",
        "  pred, scores = run_inference(model, text)\n",
        "  end = time.perf_counter()\n",
        "  latency_ms = (end - start) * 1000\n",
        "  return pred, scores, latency_ms\n",
        "\n",
        "### Empirical Scaling (computational efficiency): merge with timed_predict later\n",
        "def benchmark(model, texts, repeats=1):\n",
        "  \"\"\"\n",
        "  texts: list[str]\n",
        "  repeats: number of repeated runs for stability\n",
        "  Returns:\n",
        "    throughput (sent/sec),\n",
        "    mean_latency_ms,\n",
        "    std_latency_ms\n",
        "  \"\"\"\n",
        "  latencies = []\n",
        "\n",
        "  for _ in range(repeats):\n",
        "    start = time.perf_counter()\n",
        "    for t in texts:\n",
        "      run_inference(model, t)\n",
        "    end = time.perf_counter()\n",
        "    latencies.append((end - start) * 1000)\n",
        "\n",
        "  mean_latency_ms = statistics.mean(latencies) / len(texts)\n",
        "  std_latency_ms = statistics.stdev(latencies) / len(texts) if len(latencies) > 1 else 0\n",
        "  throughput = 1000 / mean_latency_ms\n",
        "\n",
        "  return throughput, mean_latency_ms,  std_latency_ms"
      ],
      "metadata": {
        "id": "n8ei40HebqVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example Usage (Single-sample evaluation)"
      ],
      "metadata": {
        "id": "S6YJHMUIPLGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = QISingleLID(BIGRAMS_CSV_PATH) # or use a link in double quotes\n",
        "\n",
        "# text = \"Ɔdɔ ne ahotɔ nkwa mu adeɛ a ɛsom bo.\"\n",
        "# true_lang = \"twi\"\n",
        "\n",
        "# pred, scores, latency = timed_predict(model, text)\n",
        "# probs = normalize_scores(scores)\n",
        "\n",
        "# print(\"Predicted:\", pred)\n",
        "# print(\"Probabilities:\", probs)\n",
        "# print(\"Accuracy:\", accuracy(pred, true_lang))\n",
        "# print(\"NLL Loss:\", nll_loss(probs, true_lang))\n",
        "# print(\"QCM:\", quantum_confidence_margin(scores))\n",
        "# print(\"Entropy:\", entropy(probs))\n",
        "# print(\"Purity:\", purity(probs))\n",
        "# print(\"Leakage:\", leakage(probs, pred))\n",
        "# print(f\"Inference Time: {latency:.2f} ms\")\n",
        "# print(f\"Speed Benchmark:\", benchmark(model, text))"
      ],
      "metadata": {
        "id": "88Ntq2T2PO2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model with IDF (Inverse Document Frequency)\n",
        "\n",
        "\\(IDF(t)=\\log \\left(\\frac{\\text{Total\\ number\\ of\\ documents}}{\\text{Number\\ of\\ documents\\ containing\\ term\\ }t}\\right)\\)\n",
        "\n",
        "Fixes equal treatment of bigrams"
      ],
      "metadata": {
        "id": "lY8EiUIdWEeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QuantumInspiredBigramLIDWithIDF:   # not used, poor quantum performance\n",
        "  model_type = \"qi\"\n",
        "  \"\"\"\n",
        "  Quantum-inspired bigram language identifier using\n",
        "  state overlap with IDF weighting.\n",
        "  \"\"\"\n",
        "  def __init__(self, bigrams_csv, alpha=1.0):\n",
        "    print(\"Loading and building quantum-inspired language states with IDF...\")\n",
        "\n",
        "    df = pd.read_csv(\n",
        "        bigrams_csv,\n",
        "        usecols=[\"lang_id\", \"lang\", \"ngram\", \"count\"],\n",
        "        dtype={\n",
        "            \"lang_id\": \"int16\",\n",
        "            \"lang\": \"category\",\n",
        "            \"ngram\": \"object\",\n",
        "            \"count\": \"int32\",\n",
        "        }\n",
        "        )\n",
        "\n",
        "    self.lang_id_to_name = {}\n",
        "    self.lang_states = {}   # lang_id -> {bigram: amplitude}\n",
        "    self.languages = []\n",
        "    self.unk_amp = {}   # lang_id -> amplitude\n",
        "    self.df = defaultdict(int)  # document frequency\n",
        "    self.total_docs = 0\n",
        "\n",
        "    # Build language state vectors per language + IDF stats\n",
        "    for lang_id, group in df.groupby(\"lang_id\"):\n",
        "      self.total_docs += 1\n",
        "\n",
        "      unique_bigrams = set(group[\"ngram\"])\n",
        "      for b in unique_bigrams:\n",
        "        self.df[b] += 1\n",
        "\n",
        "      lang_name = group[\"lang\"].iloc[0]\n",
        "      self.lang_id_to_name[lang_id] = lang_name\n",
        "      self.languages.append(lang_id)\n",
        "\n",
        "      counts = group.set_index(\"ngram\")[\"count\"].to_dict()\n",
        "      total = sum(counts.values()) + alpha * len(counts)\n",
        "\n",
        "      self.unk_amp[lang_id] = math.sqrt(alpha / total)\n",
        "\n",
        "      # Compute sqrt-prob amplitudes\n",
        "      state = {}\n",
        "      for bigram, count in counts.items():\n",
        "        prob = (count + alpha) / total\n",
        "        state[bigram] = math.sqrt(prob)\n",
        "\n",
        "      # L2 normalize (safety)\n",
        "      norm = math.sqrt(sum(v * v for v in state.values()))\n",
        "      for b in state:\n",
        "        state[b] /= norm\n",
        "\n",
        "      self.lang_states[lang_id] = state\n",
        "\n",
        "    self.word_re = re.compile(r\"\\w+\", flags=re.UNICODE)\n",
        "\n",
        "    del df\n",
        "    gc.collect()\n",
        "\n",
        "    print(f\"Loaded {len(self.languages)} language states.\")\n",
        "    print(\"Total docs:\", self.total_docs)\n",
        "    print(\"Sample DF entries:\", list(self.df.items())[:5])\n",
        "\n",
        "  # === IDF Function\n",
        "  def idf(self, bigram):\n",
        "    return math.log((self.total_docs + 1) / (1+ self.df.get(bigram, 0))) + 1.0\n",
        "\n",
        "  # === Sentence -> State Encoding (Sparse)\n",
        "  def extract_bigrams(self, text):\n",
        "    words = self.word_re.findall(text)\n",
        "    return [f\"{words[i]} {words[i+1]}\" for i in range(len(words) - 1)]\n",
        "\n",
        "  def sentence_state(self, text):\n",
        "    bigrams = self.extract_bigrams(text)\n",
        "    if not bigrams:\n",
        "      return None\n",
        "\n",
        "    freq = defaultdict(int)\n",
        "    for b in bigrams:\n",
        "      freq[b] += 1\n",
        "\n",
        "    total = sum(freq.values())\n",
        "\n",
        "    # sqrt frequency amplitudes (with idf)\n",
        "    state = {}\n",
        "    for b, c in freq.items():\n",
        "      tf = c / total\n",
        "      w_idf = self.idf(b)\n",
        "      state[b] = math.sqrt(tf * w_idf)\n",
        "\n",
        "    # normalize\n",
        "    norm = math.sqrt(sum(v*v for v in state.values()))\n",
        "    for b in state:\n",
        "      state[b] /= norm\n",
        "\n",
        "    return state\n",
        "\n",
        "  # === Quantum-Inspired Measurement (Fast Overlap)\n",
        "  def predict(self, text):\n",
        "    s_state = self.sentence_state(text)\n",
        "    if s_state is None:\n",
        "      return None, {}\n",
        "\n",
        "    best_lang = None\n",
        "    best_score = -1.0\n",
        "    scores = {}\n",
        "\n",
        "    for lang_id in self.languages:\n",
        "      l_state = self.lang_states[lang_id]\n",
        "\n",
        "      # dot product over sentence support only\n",
        "      overlap = 0.0\n",
        "      for b, a_s in s_state.items():\n",
        "        a_l = l_state.get(b, self.unk_amp[lang_id])  # assign a small non-zero amplitude when a bigram is unseen\n",
        "        overlap += a_l * a_s\n",
        "\n",
        "      score = overlap * overlap   # |⟨v_l | v_s⟩|^2\n",
        "      scores[self.lang_id_to_name[lang_id]] = score\n",
        "\n",
        "      if score > best_score:\n",
        "        best_score = score\n",
        "        best_lang = self.lang_id_to_name[lang_id]\n",
        "\n",
        "    # print(\"[def predict] Sentence bigrams:\", list(s_state.keys())[:10])\n",
        "    # print(\"[def predict] Lang vocab sample:\", list(l_state.keys())[:10])\n",
        "\n",
        "    return best_lang, scores"
      ],
      "metadata": {
        "id": "Ro4t9ILWZ44a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# idf_model = QuantumInspiredBigramLIDWithIDF(BIGRAMS_CSV_PATH)\n",
        "\n",
        "# text = \"Ɔdɔ ne ahotɔ nkwa mu adeɛ a ɛsom bo.\"\n",
        "# true_lang = \"twi\"\n",
        "\n",
        "# pred, scores, latency = timed_predict(idf_model, text)\n",
        "# probs = normalize_scores(scores)\n",
        "\n",
        "# print(\"Predicted:\", pred)\n",
        "# print(\"Probabilities:\", probs)\n",
        "# print(\"Accuracy:\", accuracy(pred, true_lang))\n",
        "# print(\"NLL Loss:\", nll_loss(probs, true_lang))\n",
        "# print(\"QCM:\", quantum_confidence_margin(scores))\n",
        "# print(\"Entropy:\", entropy(probs))\n",
        "# print(\"Purity:\", purity(probs))\n",
        "# print(\"Leakage:\", leakage(probs, pred))\n",
        "# print(f\"Inference Time: {latency:.2f} ms\")\n",
        "# print(f\"Speed Benchmark:\", benchmark(idf_model, text))"
      ],
      "metadata": {
        "id": "oLC6mykmtwDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Benchmarking Against Hackathon's Baseline"
      ],
      "metadata": {
        "id": "snCcj6ne67gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageIdentifier:\n",
        "    model_type = \"baseline\"\n",
        "    def __init__(self, bigrams_csv):\n",
        "        \"\"\"Load bigram frequencies from CSV and build language models.\"\"\"\n",
        "        print(\"Loading bigram data...\")\n",
        "\n",
        "        # Memory-efficient CSV reading with explicit dtypes\n",
        "        df = pd.read_csv(bigrams_csv,\n",
        "                        usecols=['lang_id', 'lang', 'ngram', 'count'],\n",
        "                        dtype={'lang_id': 'int16', 'lang': 'category',\n",
        "                               'ngram': 'object', 'count': 'int32'})\n",
        "\n",
        "        self.lang_id_to_name = {}\n",
        "        self.lang_log_probs = {}\n",
        "        self.languages = []\n",
        "\n",
        "        # Process by language group to avoid redundant storage\n",
        "        for lang_id, group in df.groupby('lang_id'):\n",
        "            lang_name = group['lang'].iloc[0]\n",
        "            self.lang_id_to_name[lang_id] = lang_name\n",
        "            self.languages.append(lang_id)\n",
        "\n",
        "            total = group['count'].sum()\n",
        "            vocab_size = len(group)\n",
        "\n",
        "            # Store ONLY log probabilities directly (no duplicate count storage)\n",
        "            log_probs = {}\n",
        "            unk_log_prob = math.log(1 / (total + vocab_size))\n",
        "\n",
        "            # Pre-calculate denominator for speed\n",
        "            denom = total + vocab_size\n",
        "\n",
        "            for _, row in group.iterrows():\n",
        "                bigram = row['ngram']\n",
        "                count = row['count']\n",
        "                log_probs[bigram] = math.log((count + 1) / denom)\n",
        "\n",
        "            log_probs['__UNK__'] = unk_log_prob\n",
        "            self.lang_log_probs[lang_id] = log_probs\n",
        "\n",
        "        self.word_re = re.compile(r\"\\w+\", flags=re.UNICODE)\n",
        "        print(f\"Loaded {len(self.languages)} languages: {list(self.lang_id_to_name.values())}\")\n",
        "\n",
        "        # CRITICAL: Explicitly free the large DataFrame from memory\n",
        "        del df\n",
        "        gc.collect()\n",
        "        print(\"Memory cleanup completed.\")\n",
        "\n",
        "    def extract_bigrams(self, text):\n",
        "        \"\"\"Extract word bigrams from text.\"\"\"\n",
        "        words = self.word_re.findall(text)\n",
        "        # List comprehension is memory-efficient here\n",
        "        return [f\"{words[i]} {words[i+1]}\" for i in range(len(words) - 1)]\n",
        "\n",
        "    def predict(self, text):\n",
        "        \"\"\"\n",
        "        Predict language and return lang_id.\n",
        "        Returns:\n",
        "          pred_lang_id (int)\n",
        "          probs (dict[int, float])  # normalized probabilities\n",
        "        \"\"\"\n",
        "        bigrams = self.extract_bigrams(text)\n",
        "\n",
        "        if not bigrams:\n",
        "            return None, {}\n",
        "\n",
        "        scores = {}\n",
        "\n",
        "        # Use direct comparison instead of dict storage for scores\n",
        "        best_lang = None\n",
        "        best_score = float('-inf')\n",
        "\n",
        "        for lang_id in self.languages:\n",
        "            log_prob = 0.0\n",
        "            lang_probs = self.lang_log_probs[lang_id]\n",
        "\n",
        "            # Local variable lookup for speed\n",
        "            for bigram in bigrams:\n",
        "                log_prob += lang_probs.get(bigram, lang_probs['__UNK__'])\n",
        "\n",
        "            # length-normalized (BLEU-style)\n",
        "            scores[lang_id] = log_prob / len(bigrams)\n",
        "\n",
        "            # avg_log_prob = log_prob / len(bigrams)\n",
        "\n",
        "            # if avg_log_prob > best_score:\n",
        "            #     best_score = avg_log_prob\n",
        "            #     best_lang = lang_id\n",
        "\n",
        "        pred = max(scores, key=scores.get)\n",
        "        return pred, scores\n",
        "\n",
        "        # return best_lang"
      ],
      "metadata": {
        "id": "qWMeJOgE9d1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single-Sentence BigramsID Evaluation Plots (Baseline vs Quantum-Inspired)"
      ],
      "metadata": {
        "id": "KJOjzQsm2wLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# standard evaluation function for single-sentence models\n",
        "def evaluate_models(\n",
        "    model,\n",
        "    model_name,\n",
        "    texts,\n",
        "    true_langs=None,\n",
        "    benchmark_repeats=3\n",
        "):\n",
        "    preds, all_scores, all_probs = [], [], []\n",
        "\n",
        "    for t in texts:\n",
        "        pred, scores, _ = timed_predict(model, t)\n",
        "        preds.append(pred)\n",
        "        all_scores.append(scores)\n",
        "\n",
        "        # Only normalize if meaningful\n",
        "        if getattr(model, \"model_type\", \"\") == \"baseline\":\n",
        "            all_probs.append(normalize_scores(scores))\n",
        "\n",
        "    throughput, mean_latency, std_latency = benchmark(\n",
        "        model, texts, repeats=benchmark_repeats\n",
        "    )\n",
        "\n",
        "    metrics = {\n",
        "        \"name\": model_name,\n",
        "        \"num_samples\": len(texts),\n",
        "        \"throughput\": throughput,\n",
        "        \"latency_ms\": mean_latency,\n",
        "        \"latency_std_ms\": std_latency,\n",
        "    }\n",
        "\n",
        "    # ---- Supervised metrics\n",
        "    if true_langs is not None:\n",
        "        metrics[\"accuracy\"] = accuracy(preds, true_langs)\n",
        "\n",
        "        if getattr(model, \"model_type\", \"\") == \"baseline\":\n",
        "            metrics[\"nll\"] = sum(\n",
        "                nll_loss(p, y) for p, y in zip(all_probs, true_langs)\n",
        "            ) / len(texts)\n",
        "\n",
        "    # ---- Quantum diagnostics (QI only)\n",
        "    if getattr(model, \"model_type\", \"\") == \"qi\":\n",
        "        metrics.update({\n",
        "            \"qcm\": sum(\n",
        "                quantum_confidence_margin(s) for s in all_scores\n",
        "            ) / len(texts),\n",
        "\n",
        "            \"purity\": sum(\n",
        "                purity(normalize_scores(s)) for s in all_scores\n",
        "            ) / len(texts),\n",
        "        })\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# reusable single-metric bar plot function\n",
        "def plot_metric(\n",
        "    models_metrics,\n",
        "    metric_key,\n",
        "    ylabel,\n",
        "    title,\n",
        "    ylim=None,\n",
        "    log_scale=False\n",
        "):\n",
        "    assert all(metric_key in m for m in models_metrics)\n",
        "\n",
        "    model_names = [m[\"name\"] for m in models_metrics]\n",
        "    values = [m[metric_key] for m in models_metrics]\n",
        "\n",
        "    plt.figure()\n",
        "    plt.bar(model_names, values)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    if log_scale:\n",
        "      plt.yscale(\"log\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "c3wAKU3D_IDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Experiment 1]: Single Sentence Benchmarking or Evaluation"
      ],
      "metadata": {
        "id": "L4b_K-Tz2vY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Hackathon baseline (single sentence) ---\n",
        "baseline_single_model = BigramLanguageIdentifier(BIGRAMS_CSV_PATH)\n",
        "\n",
        "baseline_single_metrics = evaluate_models(\n",
        "    model=baseline_single_model,\n",
        "    model_name=\"Baseline-Single\",\n",
        "    texts=[\"Ɔdɔ ne ahotɔ nkwa mu adeɛ a ɛsom bo.\"],\n",
        "    true_langs=[\"twi\"]\n",
        ")\n",
        "\n",
        "# --- Quantum-inspired single sentence ---\n",
        "qi_single_model = QISingleLID(BIGRAMS_CSV_PATH)\n",
        "\n",
        "qi_single_metrics = evaluate_models(\n",
        "    model=qi_single_model,\n",
        "    model_name=\"QI-Single\",\n",
        "    texts=[\"Ɔdɔ ne ahotɔ nkwa mu adeɛ a ɛsom bo.\"],\n",
        "    true_langs=[\"twi\"]\n",
        ")\n",
        "\n",
        "single_sentence_metrics = [\n",
        "    baseline_single_metrics,\n",
        "    qi_single_metrics\n",
        "]\n",
        "\n",
        "print(\"===== Single-Sentence Models =====\")\n",
        "for metrics in single_sentence_metrics:\n",
        "    print(f\"\\n--- {metrics['name']} ---\")\n",
        "    for k, v in metrics.items():\n",
        "        if k not in [\"scores\", \"probs\"]:\n",
        "            print(f\"{k}: {v}\")"
      ],
      "metadata": {
        "id": "L2mnxu4t4OAa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "outputId": "c9162995-905b-4010-f4f9-424467039b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading bigram data...\n",
            "Loaded 3 languages: ['twi', 'eng', 'fra']\n",
            "Memory cleanup completed.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'values'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4243567265.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbaseline_single_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBigramLanguageIdentifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBIGRAMS_CSV_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m baseline_single_metrics = evaluate_models(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseline_single_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Baseline-Single\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3757342284.py\u001b[0m in \u001b[0;36mevaluate_models\u001b[0;34m(model, model_name, texts, true_langs, benchmark_repeats)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Only normalize if meaningful\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"baseline\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mall_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     throughput, mean_latency, std_latency = benchmark(\n",
            "\u001b[0;32m/tmp/ipython-input-4273872817.py\u001b[0m in \u001b[0;36mnormalize_scores\u001b[0;34m(scores, eps)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m### Function to normalize scores into a probability distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalize_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meps\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Single-sentence metrics plotting\n",
        "\n",
        "plot_metric(\n",
        "    models_metrics=single_sentence_metrics,\n",
        "    metric_key=\"accuracy\",\n",
        "    ylabel=\"Accuracy\",\n",
        "    title=\"Single-Sentence Accuracy Comparison\",\n",
        "    ylim=(0, 1)\n",
        ")\n",
        "\n",
        "plot_metric(\n",
        "    models_metrics=single_sentence_metrics,\n",
        "    metric_key=\"latency_ms\",\n",
        "    ylabel=\"Latency (ms)\",\n",
        "    title=\"Single-Sentence Inference Latency Comparison\",\n",
        "    log_scale=True\n",
        ")\n",
        "\n",
        "plot_metric(\n",
        "    models_metrics=single_sentence_metrics,\n",
        "    metric_key=\"throughput\",\n",
        "    ylabel=\"Throughput (sent/sec)\",\n",
        "    title=\"Single-Sentence Throughput Comparison\",\n",
        "    log_scale=True\n",
        ")\n",
        "\n",
        "# plot_metric(\n",
        "#     models_metrics=single_sentence_metrics,\n",
        "#     metric_key=\"qcm\",\n",
        "#     ylabel=\"Single-Sentence Quantum Confidence Margin\",\n",
        "#     title=\"QCM Comparison\"\n",
        "# )\n",
        "\n",
        "# plot_metric(\n",
        "#     models_metrics=single_sentence_metrics,\n",
        "#     metric_key=\"entropy\",\n",
        "#     ylabel=\"Entropy\",\n",
        "#     title=\"Single-Sentence Entropy Comparison\"\n",
        "# )\n",
        "\n",
        "# plot_metric(\n",
        "#     models_metrics=single_sentence_metrics,\n",
        "#     metric_key=\"purity\",\n",
        "#     ylabel=\"Purity\",\n",
        "#     title=\"Single-Sentence Purity Comparison\"\n",
        "# )\n",
        "\n",
        "# plot_metric(\n",
        "#     models_metrics=single_sentence_metrics,\n",
        "#     metric_key=\"leakage\",\n",
        "#     ylabel=\"Leakage\",\n",
        "#     title=\"Single-Sentence Leakage Comparison\"\n",
        "# )\n",
        "\n",
        "# plot_metric(\n",
        "#     models_metrics=single_sentence_metrics,\n",
        "#     metric_key=\"nll\",\n",
        "#     ylabel=\"Negative Log-Likelihood\",\n",
        "#     title=\"Single-Sentence NLL Loss Comparison\"\n",
        "# )"
      ],
      "metadata": {
        "id": "KIAoPvEYHmOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Experiment 2]: Multiple-Sentence Evaluation"
      ],
      "metadata": {
        "id": "WxZepD0oJmjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# standard evaluation function for batch-aware models\n",
        "def evaluate_scaling(\n",
        "    model,\n",
        "    model_name,\n",
        "    texts_by_batch_size,\n",
        "    repeats=3\n",
        "):\n",
        "    \"\"\"\n",
        "    texts_by_batch_size: dict[int -> list[str]]\n",
        "    \"\"\"\n",
        "\n",
        "    batch_sizes = []\n",
        "    total_latencies = []\n",
        "    per_sample_latencies = []\n",
        "    throughputs = []\n",
        "\n",
        "    for batch_size, texts in texts_by_batch_size.items():\n",
        "        throughput, mean_latency, _ = benchmark(\n",
        "            model,\n",
        "            texts,\n",
        "            repeats=repeats\n",
        "        )\n",
        "\n",
        "        batch_sizes.append(batch_size)\n",
        "        total_latencies.append(mean_latency * batch_size)\n",
        "        per_sample_latencies.append(mean_latency)\n",
        "        throughputs.append(throughput)\n",
        "\n",
        "    return {\n",
        "        \"name\": model_name,\n",
        "        \"batch_sizes\": batch_sizes,\n",
        "        \"latencies_ms\": total_latencies,\n",
        "        \"latency_per_sample_ms\": per_sample_latencies,\n",
        "        \"throughputs\": throughputs,\n",
        "    }\n",
        "\n",
        "def plot_scaling_metric(\n",
        "    scaling_results,\n",
        "    x_key,\n",
        "    y_key,\n",
        "    xlabel,\n",
        "    ylabel,\n",
        "    title,\n",
        "    logx=True,\n",
        "    logy=True\n",
        "):\n",
        "    plt.figure()\n",
        "\n",
        "    for model_name, data in scaling_results.items():\n",
        "        plt.plot(\n",
        "            data[x_key],\n",
        "            data[y_key],\n",
        "            marker=\"o\",\n",
        "            label=model_name\n",
        "        )\n",
        "\n",
        "    if logx:\n",
        "        plt.xscale(\"log\")\n",
        "    if logy:\n",
        "        plt.yscale(\"log\")\n",
        "\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True, which=\"both\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Q0puDnGvs_JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Experiment 2]: Multiple-Sentence"
      ],
      "metadata": {
        "id": "q8lRsXuwcGpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test sentences embedded directly in code\n",
        "test_sentences = [\n",
        "    {\"sentence\": \"The sun rises in the east every morning.\", \"lang_id\": 2},\n",
        "    {\"sentence\": \"She enjoys reading books in the library.\", \"lang_id\": 2},\n",
        "    {\"sentence\": \"We are planning a trip to the mountains next month.\", \"lang_id\": 2},\n",
        "    {\"sentence\": \"The children are playing soccer in the park.\", \"lang_id\": 2},\n",
        "    {\"sentence\": \"He works as a teacher at the local school.\", \"lang_id\": 2},\n",
        "    {\"sentence\": \"Le chat dort sur le canapé.\", \"lang_id\": 3},\n",
        "    {\"sentence\": \"J'aime beaucoup la musique classique.\", \"lang_id\": 3},\n",
        "    {\"sentence\": \"Nous allons au marché ce matin.\", \"lang_id\": 3},\n",
        "    {\"sentence\": \"Elle étudie la médecine à l'université.\", \"lang_id\": 3},\n",
        "    {\"sentence\": \"Il fait beau aujourd'hui.\", \"lang_id\": 3},\n",
        "    {\"sentence\": \"Owia no pue wɔ apueeɛ fam anɔpa biara.\", \"lang_id\": 1},\n",
        "    {\"sentence\": \"Ɔpɛ sɛ ɔkenkan nhoma wɔ nwomafieso hɔ.\", \"lang_id\": 1},\n",
        "    {\"sentence\": \"Yɛreyɛ nhyehyɛeɛ sɛ yɛbɛkɔ mmepɔw so ɔsram a ɛdi hɔ yi.\", \"lang_id\": 1},\n",
        "    {\"sentence\": \"Mmɔ3 no reto bɔɔlo wɔ mmrampam no mu.\", \"lang_id\": 1},\n",
        "    {\"sentence\": \"Ɔyɛ adwuma sɛ ɔkyerɛkyerɛfoɔ wɔ mpɔtam sukuu no mu.\", \"lang_id\": 1}\n",
        "]\n",
        "\n",
        "# Sentence dictionary adapter\n",
        "def unpack_sentence_dict(test_sentences, id_to_lang):\n",
        "  texts = []\n",
        "  true_langs = []\n",
        "  for item in test_sentences:\n",
        "    texts.append(item[\"sentence\"])\n",
        "    true_langs.append(id_to_lang[item[\"lang_id\"]])\n",
        "  return texts, true_langs"
      ],
      "metadata": {
        "id": "6fcM-oNxcRFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Held-Out Validation on Bigram CSV"
      ],
      "metadata": {
        "id": "lLSeAOV1c5tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define split ratio\n",
        "TRAIN_RATIO = 0.8\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# 2. Chunk-safe splitter\n",
        "train_rows = []\n",
        "heldout_rows = []\n",
        "\n",
        "rng = np.random.default_rng(RANDOM_SEED)\n",
        "\n",
        "for chunk in pd.read_csv(BIGRAMS_CSV_PATH, chunksize=CHUNK_SIZE):\n",
        "  # keep only valid word bigrams\n",
        "  chunk =  chunk[chunk[\"ngram\"].str.contains(\" \", regex=False)]\n",
        "\n",
        "  for lang_id, group in chunk.groupby(\"lang_id\"):\n",
        "    idx = np.arange(len(group))\n",
        "    rng.shuffle(idx)\n",
        "\n",
        "    split = int(TRAIN_RATIO * len(idx))\n",
        "    train_idx = idx[:split]\n",
        "    heldout_idx = idx[split:]\n",
        "\n",
        "    train_rows.append(group.iloc[train_idx])\n",
        "    heldout_rows.append(group.iloc[heldout_idx])\n",
        "\n",
        "# 3. Assemble final CSVs\n",
        "train_df = pd.concat(train_rows, ignore_index=True)\n",
        "heldout_df = pd.concat(heldout_rows, ignore_index=True)\n",
        "\n",
        "train_path = PROJECT_ROOT / \"bigrams_train_csv\"\n",
        "heldout_path = PROJECT_ROOT / \"bigrams_heldout_csv\"\n",
        "\n",
        "train_df.to_csv(train_path, index=False)\n",
        "heldout_df.to_csv(heldout_path, index=False)\n",
        "\n",
        "print(\"Saved:\")\n",
        "print(train_path)\n",
        "print(heldout_path)"
      ],
      "metadata": {
        "id": "S3NpcLendEaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating synthetic held-out sentences for prediction"
      ],
      "metadata": {
        "id": "nsOTei2YcyG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# i need to perform batching throughput of 100k+ sentences, optimize/enhance/align my code to do just that\n",
        "\n",
        "# 1. build language-specific bigram pools\n",
        "heldout_bigrams = defaultdict(list)\n",
        "\n",
        "for chunk in pd.read_csv(heldout_path, chunksize=CHUNK_SIZE):\n",
        "    for _, row in chunk.iterrows():\n",
        "        heldout_bigrams[row[\"lang\"]].append(row[\"ngram\"])\n",
        "\n",
        "# 2. language-controlled sentence controller\n",
        "def generate_sentence_from_bigrams(bigrams, length=8):\n",
        "  if len(bigrams) < length:\n",
        "    return None\n",
        "\n",
        "  chosen = random.sample(bigrams, length)\n",
        "  words = [chosen[0].split()[0]]\n",
        "  for bg in chosen:\n",
        "    words.append(bg.split()[1])\n",
        "\n",
        "  return \" \".join(words)\n",
        "\n",
        "# 3. build held-out evaluation set\n",
        "eval_texts = []\n",
        "eval_labels = []\n",
        "\n",
        "for lang, bigrams in heldout_bigrams.items():\n",
        "  for _ in range(20):  # 20 sentences per language\n",
        "    sent = generate_sentence_from_bigrams(bigrams)\n",
        "    if sent:\n",
        "      eval_texts.append(sent)\n",
        "      eval_labels.append(lang)\n",
        "\n",
        "# 4. minimal print of samples\n",
        "print(f\"Total sentences generated: {len(eval_texts)}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "combined_data = list(zip(eval_labels, eval_texts)) # combine to keep them paired\n",
        "indices = random.sample(range(len(combined_data)), min(5, len(combined_data))) # pick 5 random\n",
        "\n",
        "for i in indices:\n",
        "    lang, text = combined_data[i]\n",
        "    print(f\"[{lang}]: {text}\")"
      ],
      "metadata": {
        "id": "0VzK4iyxcUkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Experiment 3]: Batch Scaling on Heldout-Validation"
      ],
      "metadata": {
        "id": "E7Dwlo5pkJNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build batch-size views (scaling experiment)\n",
        "def build_bigram_batches(df, batch_sizes):\n",
        "    bigrams = df[\"ngram\"].values\n",
        "    return {\n",
        "        bs: bigrams[:bs]\n",
        "        for bs in batch_sizes\n",
        "        if bs <= len(bigrams)\n",
        "    }\n",
        "\n",
        "# Initialize inference batch size\n",
        "scaling_texts = [item[\"sentence\"] for item in heldout_df]  # 100k+\n",
        "\n",
        "batch_sizes = [1, 10, 100, 1_000, 10_000]\n",
        "\n",
        "texts_by_batch_size = build_bigram_batches(\n",
        "    scaling_texts,\n",
        "    batch_sizes\n",
        ")"
      ],
      "metadata": {
        "id": "vvaLZA02kMvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Hackathon batch baseline ---\n",
        "baseline_batch_model = BigramLanguageIdentifier(BIGRAMS_CSV_PATH)\n",
        "\n",
        "baseline_batch_scaling = evaluate_scaling(\n",
        "    model=baseline_batch_model,\n",
        "    model_name=\"Baseline-Batch\",\n",
        "    texts_by_batch_size=texts_by_batch_size\n",
        ")\n",
        "\n",
        "# --- Quantum-inspired batch ---\n",
        "qi_batch_model = QIBatchLID(BIGRAMS_CSV_PATH)\n",
        "\n",
        "# texts, true_langs = unpack_sentence_dict(\n",
        "#     test_sentences,\n",
        "#     qi_batch_model.lang_id_to_name\n",
        "# )\n",
        "\n",
        "# texts_by_batch_size = build_bigram_batches(texts, batch_sizes)\n",
        "\n",
        "qi_batch_scaling = evaluate_scaling(\n",
        "    model=qi_batch_model,\n",
        "    model_name=\"QI-Batch\",\n",
        "    texts_by_batch_size=texts_by_batch_size\n",
        ")\n",
        "\n",
        "scaling_results = {\n",
        "    baseline_batch_scaling[\"name\"]: baseline_batch_scaling,\n",
        "    qi_batch_scaling[\"name\"]: qi_batch_scaling,\n",
        "}\n",
        "\n",
        "print(\"===== Batch Scaling Results =====\")\n",
        "for name, data in scaling_results.items():\n",
        "    print(f\"\\n{name}\")\n",
        "    for k, v in data.items():\n",
        "        if k != \"name\":\n",
        "            print(f\"  {k}: {v}\")"
      ],
      "metadata": {
        "id": "jpTiTOwP4wu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch input metrics plotting\n",
        "plot_scaling_metric(\n",
        "    scaling_results,\n",
        "    x_key=\"batch_sizes\",\n",
        "    y_key=\"throughputs\",\n",
        "    xlabel=\"Batch Size\",\n",
        "    ylabel=\"Sentences / second\",\n",
        "    title=\"Batch Throughput Scaling\"\n",
        ")"
      ],
      "metadata": {
        "id": "uKHHvEJGblf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# per-sample latency (optional)\n",
        "plot_scaling_metric(\n",
        "    scaling_results,\n",
        "    x_key=\"batch_sizes\",\n",
        "    y_key=\"latency_per_sample_ms\",\n",
        "    xlabel=\"Batch Size\",\n",
        "    ylabel=\"Latency per sentence (ms)\",\n",
        "    title=\"Per-Sentence Latency Scaling\",\n",
        "    logy=True\n",
        ")"
      ],
      "metadata": {
        "id": "kwwI4LaAavDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the Quantum-Inspired model"
      ],
      "metadata": {
        "id": "rg8rqd_F4AOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qi_single_model_train = QISingleLID(\n",
        "    bigrams_csv=train_path\n",
        ")\n",
        "\n",
        "qi_batch_model_train = QIBatchLID(\n",
        "    bigrams_csv=train_path\n",
        ")"
      ],
      "metadata": {
        "id": "vKhINtT_3_vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the baseline model too\n",
        "baseline_model_train = BigramLanguageIdentifier(\n",
        "    bigrams_csv=train_path\n",
        ")"
      ],
      "metadata": {
        "id": "KrS9mGvUoF1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running on held-out evaluation (batch + single)"
      ],
      "metadata": {
        "id": "G60t8Et979Pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# are these initializations intuitively correct. for fairness, I wanted to train all the models on the held-out train set and test on the held-out test set. but is this sound because although i though i term it train, do the really train? i'm not storing or updating gradients, probably get wasting computing with \"the training\"\n",
        "models_to_eval = [\n",
        "    (qi_single_model_train, \"QI-Heldout-Single\"),\n",
        "    (qi_batch_model_train, \"QI-Heldout-Batch\"),\n",
        "    (baseline_model_train, \"Baseline-Heldout-Batch\"),\n",
        "]\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"HELD-OUT BIGRAM VALIDATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for model, name in models_to_eval:\n",
        "    metrics = evaluate_models(\n",
        "        model=model,\n",
        "        model_name=name,\n",
        "        texts=eval_texts,\n",
        "        true_langs=eval_labels\n",
        "    )\n",
        "\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    for k, v in metrics.items():\n",
        "        if k not in [\"scores\", \"probs\"]:\n",
        "            print(f\"{k}: {v}\")"
      ],
      "metadata": {
        "id": "INSXbLuc8G4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global output folder"
      ],
      "metadata": {
        "id": "FLOffLvaoiFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# create folder sub-directories\n",
        "ARTIFACT_DIR = Path(\"artifacts\")\n",
        "PLOTS_DIR = ARTIFACT_DIR / \"plots\"\n",
        "TABLES_DIR = ARTIFACT_DIR / \"tables\"\n",
        "\n",
        "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "TABLES_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Plot saving logic\n",
        "def save_and_show_plot(filename, dpi=300):\n",
        "  path = PLOTS_DIR / filename\n",
        "  plt.tight_layout()\n",
        "  plt.savefig(path, dpi=dpi)\n",
        "  plt.show()  # turn off\n",
        "  print(f\"Saved plot -> {path}\")"
      ],
      "metadata": {
        "id": "ZyNdz_CWiPQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_and_show_plot(\"single_sentence_accuracy.png\")  #\n",
        "save_and_show_plot(\"latency_scaling.png\")  # scaling plot saving"
      ],
      "metadata": {
        "id": "rOTs3rbtpokq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save numeric results (tables)\n",
        "pd.DataFrame(single_sentence_metrics).to_csv(\n",
        "    TABLES_DIR / \"single_sentence_metrics.csv\",\n",
        "    index=False\n",
        ")\n",
        "\n",
        "pd.DataFrame.from_dict(scaling_results, orient=\"index\").to_csv(\n",
        "    TABLES_DIR / \"scaling_results.csv\"\n",
        ")"
      ],
      "metadata": {
        "id": "vmxKN1XnqSwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zipping everthing\n",
        "\n",
        "import shutil\n",
        "\n",
        "shutil.make_archive(\n",
        "    \"evaluation_artifacts\",\n",
        "    \"zip\",\n",
        "    ARTIFACT_DIR\n",
        ")\n",
        "\n",
        "print(\"Download ready: evaluation_artifacts.zip\")"
      ],
      "metadata": {
        "id": "kHydMx_8q0P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "results = {\n",
        "    \"single\": single_sentence_metrics,\n",
        "    \"batch_scaling\": scaling_results,\n",
        "    \"heldout\": heldout_results\n",
        "}\n",
        "\n",
        "with open(\"results.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "    print(\"Saved results.json\")"
      ],
      "metadata": {
        "id": "iAfo7isT47gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"metrics_single.json\", \"w\") as f:\n",
        "    json.dump(single_sentence_metrics, f, indent=2)\n",
        "\n",
        "with open(\"metrics_scaling.json\", \"w\") as f:\n",
        "    json.dump(scaling_results, f, indent=2)"
      ],
      "metadata": {
        "id": "hmD_b8dN9Kpe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}